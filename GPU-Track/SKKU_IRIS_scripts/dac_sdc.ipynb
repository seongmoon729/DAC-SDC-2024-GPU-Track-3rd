{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAC Contest\n",
    "This reference design will help you walk through a design flow of DAC SDC 2023. This is a simplified design to help users get started on the FPGA platform and to understand the overall flow. It does not contain any object detection hardware.\n",
    "\n",
    "If you have any questions, please post on the Slack page (link on SDC website sidebar).\n",
    "\n",
    "### Hardware\n",
    "\n",
    "### Software\n",
    "Note:\n",
    "  * You will not submit your `dac_sdc.py` file, so any changes you make to this file will not be considered during evluation.  \n",
    "  * You can use both PS and PL side to do inference.\n",
    "\n",
    "### Object Detection\n",
    "\n",
    "Object detection will be done on images in batches:\n",
    "  * You will provide a Python callback function that will perform object detection on batch of images.  This callback function wile be called many times.\n",
    "  * The callback function should return the locations of all images in the batch.\n",
    "  * Runtime will be recorded during your callback function.\n",
    "  * Images will be loaded from SD card before each batch is run, and this does not count toward your energy usage or runtime.\n",
    "  \n",
    "### Notebook\n",
    "Your notebook should contain 4 code cells:\n",
    "\n",
    "1. Importing all libraries and creating your Team object.\n",
    "1. Downloading the overlay, compile the code, and performany any one-time configuration.\n",
    "1. Python callback function and any other Python helper functions.\n",
    "1. Running object detection\n",
    "1. Cleanup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Create Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../common\"))\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "import dac_sdc\n",
    "from iris_utils_v6 import TensorRTEngine\n",
    "\n",
    "team_name = 'SKKU_IRIS_GPU'\n",
    "dac_sdc.BATCH_SIZE = 1\n",
    "team = dac_sdc.Team(team_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your team directory where you can access your notebook, and any other files you submit, is available as `team.team_dir`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing the library and model\n",
    "Prepare the dependencies for the contest, including installing python packages, compiling your binaries, and linking to the notebook.\n",
    "\n",
    "Your team is responsible to make sure the correct packages are installed. For the contest environment, use the configuration below provided by Nvidia:\n",
    "- [JetPack 4.6.1](https://developer.nvidia.com/embedded/jetpack-sdk-461)\n",
    "    - Ubuntu 18.04\n",
    "    - CUDA 10.2\n",
    "    - cuDNN 8.2.1\n",
    "    - gcc 7.5.0\n",
    "    - python 3.6.9\n",
    "    - TensorRT 8.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Python Callback Function and Helper Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pushing the picture through the pipeline\n",
    "In this example, we use contiguous memory arrays for sending and receiving data via DMA.\n",
    "\n",
    "The size of the buffer depends on the size of the input or output data.  The example images are 640x360 (same size as training and test data), and we will use `pynq.allocate` to allocate contiguous memory.\n",
    "\n",
    "### Callback function\n",
    "The callback function:\n",
    "  - Will be called on each batch of images (will be called many times)\n",
    "  - Is prvided with a list of tuples of (image path, RGB image)\n",
    "  - It should return a dictionary with an entry for each image:\n",
    "    - Key: Image name (`img_path.name`)\n",
    "    - Value: Dictionary of item type and bounding box (keys: `type`, `x`, `y`, `width`, `height`)\n",
    "\n",
    "See the code below for an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callback(engine_path):\n",
    "    engine = TensorRTEngine(engine_path)\n",
    "    input_shape = engine.input_shape # (1, 3, h, w)\n",
    "\n",
    "    def callback(inputs):\n",
    "        outputs = dict()\n",
    "        for img_path, rgb_img in inputs:\n",
    "            orig_img_shape = engine.preprocess(rgb_img)\n",
    "            preds = engine.run()\n",
    "            outputs[img_path.name] = engine.postprocess(preds, orig_img_shape)\n",
    "        return outputs\n",
    "    \n",
    "    return callback, input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warmup\n",
      "warmup done\n"
     ]
    }
   ],
   "source": [
    "engine_path = 'IRIS.trt'\n",
    "\n",
    "iris_callback, input_shape = create_callback(engine_path)\n",
    "_, c, h, w = input_shape\n",
    "print(\"warmup\")\n",
    "iris_callback(\n",
    "    [(Path(''), np.random.randint(low=0, high=255, size=(h, w, c), dtype=np.uint8)) for _ in range(300)]\n",
    ")\n",
    "print(\"warmup done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Running Object Detection\n",
    "\n",
    "Call the following function to run the object detection.  Extra debug output is enabled when `debug` is `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team.run(iris_callback, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
